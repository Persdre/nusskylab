\chapter{Testing and user evaluations} \label{testing}

Testing is very important in development as it serves as the validation and verification of the program\cite{citationtesting}. In the process of continuous development, having tests helps us to catch errors, especially regression errors. Skylab as a software engineering project is covered by different levels of tests to ensure the delivered features are as promised.

Testing in GitHub flow —-- the development process adopted in Skylab —-- has a special place as well. Through continuous integration tools like Travis, each pull requests and commits on master branch will be tested and the status will be used as the indicator whether merging to master brunch should be done and the health of current master brunch.

RSpec is the testing library used in Skylab and it is widely used the testing tool for many  Rails programmers as well\cite{citationrspec}. And for tests involving database, FactoryGirl is used for creating records in databases and DataCleaner to ensure testing database is cleaned before and after tests. The syntax of FactoryGirl and RSpec is pretty expressive and concise, which aligns well with design of Rails, improving the readability of tests.

\section{Unit testing} \label{unittesting}

Models are the most fundamental components in Rails' MVC pattern and they are tested and fully covered in Skylab. In Skylab, models' testing are executed on testing database instead of faking models to test logic and validation in models only. Although this would slow down execution of test suite overall as database access is usually slow, we want to make the integration of models' logic and constraints in database work as expected. And since  the test suite of Skylab is quick to complete (less than 2 minutes to run), we favor better tested code over faster test execution.

Besides models, controllers, mailers and helpers are tested as well. The unit testing can make sure each individual component in Skylab is working as expected and also contributes the most to overall test coverage.

\section{Acceptance testing} \label{acceptancetesting}

Acceptance testing is to make sure the whole system has met the requirement specifications when users execute their various activities\cite{citationacceptancetesting}. To simulate user actions such as filling the form and clicking buttons, Capybara is the used as the testing library for acceptance testing. It is a very popular testing library written in Ruby and works well with RSpec\cite{citationcapybara}. There are different drivers used by Capybara as well. For most use cases where JavaScript execution and external resources are not required, RackTest is used as the default driver as it is lightweight and fast to run\cite{citationcapybara}. Capybara-webkit is used for those cases in which JavaScript execution is required as it supports JavaScript and it is still faster than drivers such as selenium since it can save the process of loading of an entire browser\cite{citationcapybara}.

Most use cases are covered in acceptance tests for Skylab, inclusive of: registration form submission, team invitation, admin's overview of different models in Skylab, students' submissions, peer evaluations and feedback. Although the testing coverage in Skylab is decent and that most use cases are included in acceptance testing as well, there are more details to check that need more testing coverage, such as (currently): advisers' evaluations, management of evaluating relationships, among others. Trying to cover more of these workflows in Skylab is therefore one of the main future tasks.

\section{Focus group meeting}

A focus group is a form of qualitative research in which a group of people are asked about their perceptions, opinions, beliefs, and attitudes towards a product, service, concept, advertisement, idea, or packaging\cite{citationfocusgroup}. During the middle of the first semester, we convened a focus group meeting about Skylab with two advisers and one facilitator.  The group was conducted to get advisers' suggestions and feedback on experience with Skylab. The feedback was generally positive, while there were useful suggestions and findings that helped to feed issues that were to be fixed and implemented at later rounds of development in Semester 2.

The focus group was conducted on 7th Oct 2015 and three questionnaires were designed beforehand to get advisers' opinions. During the meeting, discussions about the complete use case flow of Skylab were done and the whole meeting was recorded as well for later reference. Suggestions mentioned in the discussion and described in the responses to questionnaires are listed below, which are also documented in Skylab's repository\cite{citationskylabfocusgroup}:

\begin{itemize}
  \item Checking who had already evaluated / or sent feedback on an evaluation: we should have status columns (similar to ``dropped'' status) for submission status, peer evaluation status so that with just one glance adviser can figure out who have not submitted and remind them (this issue is still in the issue tracker);
  \item Change tab order for adviser homepage: move the current first tab to last as advisers rarely use them (this has been implemented);
  \item Forms too verbose Three radio fields take up more than one page. Suggested way of presenting options: Poor 1[?] 2[?] 3[?] 4[?] 5[?] Best(Question mark means only after the user hovers over the detailed explanation for the option will be given) (this issue is still in the issue tracker);
  \item Hosting of videos (this is not accepted as it seems to be too ambitious);
  \item Auto expand text boxes when close to full (this has been implemented);
  \item Dropdown for team selection not clear about whether the new team is being evaluated (this has been implemented);
  \item Autosave text and input / prompt for leaving page (this has been implemented);
  \item Summary composite page for the evaluation group with respect to each question for Likert scale and textboxes / Quick Fix: use anchors to jump to a particular form on a concatenated page (this issue is still in the issue tracker);
  \item ``More info'' tab in adviser homepage is misleading (this issue is still in the issue tracker);
  \item Enable users to view all past submissions, all past peer evaluations(by providing link to viewing them in some place) when you are editing/submitting a peer evaluation (this has been implemented);
  \item Evaluating relationship: explore use of D3(or similar stuff) to represent all relationships as graph (this issue is still in the issue tracker);
\end{itemize}
